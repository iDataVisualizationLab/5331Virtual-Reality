<!-- Adapted from https://www.evl.uic.edu/aej/424/ -->

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
    <title>Virtual Reality</title>
    <link rel="shortcut icon" href="../styles/oculus.png">
    <style>
        body {
            font-size: 1.25em;
        }
    </style>
</head>
<body bgcolor="white" text="black">
<div align="left"><font style="font-family:
        Helvetica,Arial,sans-serif;" color="black" size="5">Introduction:</font></div>


<li style="margin-left: 30px">
    In VR, positional tracking is an essential technology that allows a device to estimate its position relative to the environment around it.<br>
    It uses a combination of <i>hardware and software</i> to achieve the detection of its absolute position. Why both <i>hardware and software</i>?<br>
    Positional tracking track movement with six degrees of freedom (<a href="https://xinreality.com/wiki/Degrees_of_freedom">6DOF</a>).
</li>

<li style="margin-left: 30px">
Ideally we would track the users eyes directly. While that is possible, it is cumbersome, and not overly necessary.
    Instead of tracking the viewer's eyes directly, we track the position and orientation of the user's head.
    From this we determine the position and orientation of the user's two eyes.<br>
</li>

<li style="margin-left: 30px">

Positional tracking brings various benefits to the VR experience. The primary purpose of tracking is to update the visual display based on the viewers head position and orientation:
    It can change the viewpoint of the user to reflect different actions like jumping, ducking, or leaning forward; allow for an exact representation of the userâ€™s hands and other objects in the virtual environment; increase the connection between the physical and virtual world by, for example, using hand position to move virtual objects by touch; and detect gestures by analyzing position over time.
</li>
<li style="margin-left: 30px">
    From users' perspective, we want to
    <ol>
        <li>Track the user's hand(s), fingers, legs, or other interface devices. Which one in the user choice presentations? </li>
        <li>Be able to move freely with few encumbrances (tracking to be as 'invisible' as possible to the user).</li>
        <li>Have minimal delay between movement of an object (including the head and hand) </li>
        <li>Want tracking to be accurate (1mm and 1 degree) </li>
    </ol>
    <p style="font-family: Helvetica,Arial,sans-serif; text-align:
      justify;"><center><img style="width: 40%" alt="retinal
        variables" src="https://www.evl.uic.edu/aej/491/pics/defanti.headtracker.jpg"><br>
                <small>Image is retrieved from <a href="https://www.evl.uic.edu/aej/491/pics/defanti.headtracker.jpg">EVL</a> at UIC </small></center></p>

</li>


<br>
<hr
        style="width: 100%; height: 1px;">
<div align="left"><font style="font-family:
        Helvetica,Arial,sans-serif;" color="black" size="5">Methods of positional tracking:</font></div>

https://www.youtube.com/watch?v=abTo0JpjNyg<br>
https://www.evl.uic.edu/aej/491/pics/defanti.headtracker.jpg<br>
https://xinreality.com/wiki/Positional_tracking<br>
https://www.nap.edu/read/4761/chapter/9#199<br>
https://www.nap.edu/read/4761/chapter/9#189<br>
https://www.roadtovr.com/overview-of-positional-tracking-technologies-virtual-reality/<br>



<hr
        style="width: 100%; height: 1px;">
Some contents on this page were adapted from <a href="https://xinreality.com/wiki/Positional_tracking"> online resources</a>
</a> and Virtual and Augmented Reality class at UIC by <a href="https://www.evl.uic.edu/aej/">Prof. Andrew Johnson</a>.

<div align="right"><font style="font-family:
        Helvetica,Arial,sans-serif;" color="black" size="2">&copy; Last revised: March 7, 2018  &nbsp; &nbsp; &&nbsp;</font></div>






</body>
</html>
